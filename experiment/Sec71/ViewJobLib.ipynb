{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入必要的库\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "\n",
    "# 导入自定义模块\n",
    "import MyNet\n",
    "from MyNet import NetList, DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_model(file_path):\n",
    "    try:\n",
    "        data = joblib.load(file_path)\n",
    "        print(\"File loaded successfully\")\n",
    "        \n",
    "        print(\"\\nData Structure Analysis:\")\n",
    "        for key, value in data.items():\n",
    "            print(f\"\\n{key}:\")\n",
    "            if isinstance(value, NetList):\n",
    "                print(f\"  Type: NetList containing {len(value)} models\")\n",
    "                print(f\"  First model type: {type(value.models[0])}\")\n",
    "            elif isinstance(value, list):\n",
    "                print(f\"  Type: list of length {len(value)}\")\n",
    "                if value:\n",
    "                    print(f\"  First item type: {type(value[0])}\")\n",
    "            elif isinstance(value, np.ndarray):\n",
    "                print(f\"  Type: numpy array of shape {value.shape}\")\n",
    "            elif isinstance(value, (int, float)):\n",
    "                print(f\"  Type: {type(value)}, Value: {value}\")\n",
    "            else:\n",
    "                print(f\"  Type: {type(value)}\")\n",
    "        \n",
    "        if 'train_losses' in data and 'main_losses' in data:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(data['train_losses'], label='Training Loss')\n",
    "            plt.plot(np.arange(0, len(data['train_losses']), len(data['train_losses'])//len(data['main_losses'])), \n",
    "                     data['main_losses'], label='Validation Loss')\n",
    "            plt.xlabel('Training Steps')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training and Validation Losses')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig('loss_plot.png')\n",
    "            plt.close()\n",
    "            print(\"\\nLoss plot saved as 'loss_plot.png'\")\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error during loading or analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_report(res: Dict[str, Any]) -> str:\n",
    "    report = \"实验数据分析报告\\n\" + \"================\\n\\n\"\n",
    "    # 1. 训练信息\n",
    "    report += \"1. 训练信息\\n\"\n",
    "    report += \"-------------\\n\"\n",
    "    epochs = len(res['info']) / (200 / len(res['info'][0]['idx']))\n",
    "    report += f\"总训练轮数 (epochs): {epochs:.1f}\\n\"\n",
    "    report += f\"每轮步数: {200 / len(res['info'][0]['idx']):.0f}\\n\"\n",
    "    report += f\"批次大小: {len(res['info'][0]['idx'])}\\n\"\n",
    "    report += f\"总训练步数: {len(res['info'])}\\n\\n\"\n",
    "\n",
    "    # 2. 模型信息\n",
    "    report += \"2. 模型信息\\n\"\n",
    "    report += \"-------------\\n\"\n",
    "    report += f\"模型类型: {type(res['models'])}\\n\"\n",
    "    report += f\"保存的模型数量: {len(res['models'])}\\n\\n\"\n",
    "\n",
    "    # 3. 损失信息\n",
    "    report += \"3. 损失信息\\n\"\n",
    "    report += \"-------------\\n\"\n",
    "    report += \"主模型损失:\\n\"\n",
    "    report += f\"  类型: {type(res['main_losses'])}\\n\"\n",
    "    report += f\"  记录次数: {len(res['main_losses'])}\\n\"\n",
    "    report += f\"  最终损失: {res['main_losses'][-1]:.4f}\\n\\n\"\n",
    "    report += \"训练损失:\\n\"\n",
    "    report += f\"  类型: {type(res['train_losses'])}\\n\"\n",
    "    report += f\"  形状: {res['train_losses'].shape}\\n\"\n",
    "    report += f\"  最终损失: {res['train_losses'][-1]:.4f}\\n\\n\"\n",
    "\n",
    "    # 4. 反事实分析\n",
    "    report += \"4. 反事实分析\\n\"\n",
    "    report += \"-------------\\n\"\n",
    "    report += f\"分析的样本数: {len(res['counterfactual'])}\\n\"\n",
    "    report += f\"每个样本的模型状态数: {len(res['counterfactual'][0])}\\n\\n\"\n",
    "\n",
    "    # 5. 其他信息\n",
    "    report += \"5. 其他信息\\n\"\n",
    "    report += \"-------------\\n\"\n",
    "    report += f\"Alpha 值: {res['alpha']}\\n\"\n",
    "\n",
    "    return report\n",
    "\n",
    "def generate_combined_loss_plot(res: Dict[str, Any], save_path: str):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Calculate epochs and steps\n",
    "    epochs = len(res['info']) / (200 / len(res['info'][0]['idx']))\n",
    "    steps_per_epoch = 200 / len(res['info'][0]['idx'])\n",
    "\n",
    "    # Training loss plot\n",
    "    x_train = np.arange(len(res['train_losses'])) / steps_per_epoch\n",
    "    ax.plot(x_train, res['train_losses'], label='Training Loss', alpha=0.7)\n",
    "\n",
    "    # Main model loss plot\n",
    "    x_main = np.arange(len(res['main_losses']))\n",
    "    ax.plot(x_main, res['main_losses'], label='Main Model Loss', alpha=0.7)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_title('Training and Main Model Losses vs. Epochs', fontsize=16)\n",
    "    ax.set_xlabel('Epochs', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "    # Add text with additional information\n",
    "    info_text = f\"Total Epochs: {epochs:.1f}\\n\" \\\n",
    "                f\"Steps per Epoch: {steps_per_epoch:.0f}\\n\" \\\n",
    "                f\"Batch Size: {len(res['info'][0]['idx'])}\\n\" \\\n",
    "                f\"Alpha: {res['alpha']}\"\n",
    "    ax.text(0.95, 0.95, info_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Loss plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载成功\n",
      "数据键: dict_keys(['models', 'info', 'counterfactual', 'alpha', 'main_losses', 'train_losses'])\n",
      "实验数据分析报告\n",
      "================\n",
      "\n",
      "1. 训练信息\n",
      "-------------\n",
      "总训练轮数 (epochs): 12.0\n",
      "每轮步数: 10\n",
      "批次大小: 20\n",
      "总训练步数: 120\n",
      "\n",
      "2. 模型信息\n",
      "-------------\n",
      "模型类型: <class 'MyNet.NetList'>\n",
      "保存的模型数量: 121\n",
      "\n",
      "3. 损失信息\n",
      "-------------\n",
      "主模型损失:\n",
      "  类型: <class 'list'>\n",
      "  记录次数: 13\n",
      "  最终损失: 0.1119\n",
      "\n",
      "训练损失:\n",
      "  类型: <class 'numpy.memmap'>\n",
      "  形状: (121,)\n",
      "  最终损失: 0.0090\n",
      "\n",
      "4. 反事实分析\n",
      "-------------\n",
      "分析的样本数: 200\n",
      "每个样本的模型状态数: 121\n",
      "\n",
      "5. 其他信息\n",
      "-------------\n",
      "Alpha 值: 0.001\n",
      "\n",
      "Loss plot saved to: /home/zihan/codes/sgd-influence/experiment/Sec71/mnist_dnn/sgd000.png\n",
      "\n",
      "模型结构:\n",
      "DNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "分析结论:\n",
      "1. 模型训练过程中的损失变化已可视化，可以观察训练和验证损失的趋势。\n",
      "2. 生成的报告提供了关于模型训练的关键信息，包括训练轮数、批次大小等。\n",
      "3. 反事实分析部分显示了每个样本的模型状态数，这可能对理解模型的鲁棒性很有帮助。\n",
      "\n",
      "下一步计划:\n",
      "1. 深入分析反事实模型，比较不同样本对模型训练的影响。\n",
      "2. 考虑添加更多的可视化，例如参数分布图或学习率变化图。\n",
      "3. 如果可能，进行交叉验证或在不同数据集上测试模型的泛化能力。\n"
     ]
    }
   ],
   "source": [
    "sys.modules['MyNet'] = sys.modules[__name__]\n",
    "\n",
    "# 定义文件路径\n",
    "path = '/home/zihan/codes/sgd-influence/experiment/Sec71/mnist_dnn/sgd000.dat'\n",
    "\n",
    "# 尝试加载数据\n",
    "try:\n",
    "    res = joblib.load(path, mmap_mode='r')\n",
    "    print(\"数据加载成功\")\n",
    "    print(\"数据键:\", res.keys())\n",
    "except Exception as e:\n",
    "    print(f\"Joblib 加载失败: {e}\")\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "        print(\"Pickle 加载成功\")\n",
    "        print(\"数据键:\", res.keys())\n",
    "    except Exception as e:\n",
    "        print(f\"Pickle 加载失败: {e}\")\n",
    "        res = None\n",
    "\n",
    "if res is None:\n",
    "    print(\"无法加载数据，请检查文件路径和格式\")\n",
    "\n",
    "# 4. 数据分析\n",
    "\n",
    "if res is not None:\n",
    "    # 生成报告\n",
    "    report = generate_report(res)\n",
    "    print(report)\n",
    "\n",
    "    # 生成损失图\n",
    "    generate_combined_loss_plot(res, path.replace('.dat', '.png'))\n",
    "\n",
    "# 5. 额外分析（可选）\n",
    "\n",
    "# 这里可以添加任何额外的分析代码\n",
    "# 例如，探索模型结构，分析特定参数等\n",
    "\n",
    "# 示例：打印模型结构（如果适用）\n",
    "if 'models' in res and isinstance(res['models'], NetList):\n",
    "    print(\"\\n模型结构:\")\n",
    "    print(res['models'].models[0])  # 假设第一个模型代表整体结构\n",
    "\n",
    "# 6. 结论和下一步\n",
    "\n",
    "print(\"\\n分析结论:\")\n",
    "print(\"1. 模型训练过程中的损失变化已可视化，可以观察训练和验证损失的趋势。\")\n",
    "print(\"2. 生成的报告提供了关于模型训练的关键信息，包括训练轮数、批次大小等。\")\n",
    "print(\"3. 反事实分析部分显示了每个样本的模型状态数，这可能对理解模型的鲁棒性很有帮助。\")\n",
    "\n",
    "print(\"\\n下一步计划:\")\n",
    "print(\"1. 深入分析反事实模型，比较不同样本对模型训练的影响。\")\n",
    "print(\"2. 考虑添加更多的可视化，例如参数分布图或学习率变化图。\")\n",
    "print(\"3. 如果可能，进行交叉验证或在不同数据集上测试模型的泛化能力。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
